{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import typing as t\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ssvr.enrich_trials\n",
    "import ssvr.qc\n",
    "import ssvr.utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ssvr.visualization as viz\n",
    "from ssvr.dataset import SessionDataset, create_session_info\n",
    "from ssvr.models import DataLoadingSettings\n",
    "\n",
    "logging.getLogger(\"ssvr\").setLevel(logging.ERROR)\n",
    "\n",
    "logging.getLogger(\"aind_behavior_services.base\").setLevel(logging.ERROR)\n",
    "\n",
    "choice_linestyle = {True: \"-\", False: \"--\"}\n",
    "subject_colors = {\"808619\": \"C2\", \"808728\": \"C3\", \"789917\": \"C4\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ee91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = DataLoadingSettings()\n",
    "DERIVED_PATH = settings.root_derived_path\n",
    "\n",
    "if False:  # Run this cell if you want to sync all dataset locally\n",
    "    from ssvr.s3_utils import sync_dataset\n",
    "\n",
    "    sync_dataset(settings)\n",
    "\n",
    "session_datasets: list[SessionDataset] = []\n",
    "for entry in tqdm(settings.sessions_to_load, desc=\"Loading sessions\", total=len(settings.sessions_to_load)):\n",
    "    candidate_paths = [p / entry.session_id for p in settings.root_path if p.exists()]\n",
    "    if not candidate_paths:\n",
    "        raise FileNotFoundError(f\"Session {entry.session_id} not found in any root path.\")\n",
    "    if len(candidate_paths) > 1:\n",
    "        logging.warning(f\"Multiple paths found for session {entry.session_id}, using the first one.\")\n",
    "    info = create_session_info(candidate_paths[0])\n",
    "    try:\n",
    "        _session = SessionDataset(session_info=info, processing_settings=settings.processing_settings)\n",
    "        if not _session.session_metrics.session_duration < datetime.timedelta(minutes=15):\n",
    "            if entry.crop_max_trials is not None:\n",
    "                _session.trials = _session.trials[: int(entry.crop_max_trials)]\n",
    "            session_datasets.append(_session)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load session {info.session_id}: {e}\")\n",
    "\n",
    "for session in tqdm(session_datasets, desc=\"Enriching sessions\"):\n",
    "    enriched_trials = ssvr.enrich_trials.enrich_with_session_type(session)  # is_fixed_stop_duration\n",
    "    enriched_trials = ssvr.enrich_trials.enrich_with_block_info(session)\n",
    "    enriched_trials = ssvr.enrich_trials.enrich_with_relative_to_block(session)\n",
    "    enriched_trials = ssvr.enrich_trials.enrich_with_previous_trial(session, n_previous=5)\n",
    "    enriched_trials = ssvr.enrich_trials.enrich_with_block_probability(session)\n",
    "    enriched_trials = ssvr.enrich_trials.enrich_with_reward_rate(session, exponential_decay=0.2)\n",
    "\n",
    "if 0:\n",
    "    ssvr.qc.run_qc(session_datasets=session_datasets, path=DERIVED_PATH / \"qc_reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25611f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials = []\n",
    "for session in session_datasets:\n",
    "    df = session.trials.copy()\n",
    "    df = df.reset_index().rename(columns={\"index\": \"trial_number\"})\n",
    "    df[\"subject\"] = session.session_info.subject\n",
    "    df[\"session_id\"] = session.session_info.session_id\n",
    "    all_trials.append(df)\n",
    "\n",
    "all_trials_df = t.cast(pd.DataFrame, pd.concat(all_trials, ignore_index=True))\n",
    "# all_trials_df.to_csv(DERIVED_PATH / \"all_sessions_enriched_trials.csv\")\n",
    "print(all_trials_df.info())\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Total trials across all sessions: {len(all_trials_df)}\")\n",
    "print(f\"Number of sessions: {all_trials_df['session_id'].nunique()}\")\n",
    "print(f\"Number of subjects: {all_trials_df['subject'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# Print per-subject statistics\n",
    "for subject in sorted(all_trials_df[\"subject\"].unique()):\n",
    "    subject_df = all_trials_df[all_trials_df[\"subject\"] == subject]\n",
    "    n_sessions = subject_df[\"session_id\"].nunique()\n",
    "    n_trials = len(subject_df)\n",
    "    print(f\"Subject {subject}: {n_sessions} sessions, {n_trials} trials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssvr.analysis.block_switching_behavior import (\n",
    "    calculate_choice_matrix,\n",
    "    plot_block_switch_choice_patterns,\n",
    ")\n",
    "\n",
    "trial_window = (-10, 30)\n",
    "choice_behavior_matrix, switch_trials_df = calculate_choice_matrix(\n",
    "    all_trials_df, trial_window=trial_window, block_switch_filter=\"different\"\n",
    ")\n",
    "\n",
    "\n",
    "with viz.a_lot_of_style():\n",
    "    fig, ax = plot_block_switch_choice_patterns(choice_behavior_matrix, trial_window)\n",
    "\n",
    "    # Add subject markers to both heatmaps\n",
    "    for heatmap_ax in ax[:2]:  # First two axes are the heatmaps\n",
    "        for s in switch_trials_df[\"subject\"].unique():\n",
    "            subject_rows = switch_trials_df[switch_trials_df[\"subject\"] == s][\"index_ord\"].values\n",
    "            color = subject_colors[s]\n",
    "            for row in subject_rows:\n",
    "                heatmap_ax.plot(-1.5, row, \"o\", color=color, markersize=4, clip_on=False)\n",
    "\n",
    "    fig.suptitle(\"All subjects\")\n",
    "    fig.savefig(DERIVED_PATH / \"block_switch_choice_patterns_all_subjects.svg\")\n",
    "\n",
    "\n",
    "with viz.a_lot_of_style():\n",
    "    for subject, df in switch_trials_df.groupby(\"subject\"):\n",
    "        fig, ax = plot_block_switch_choice_patterns(\n",
    "            choice_behavior_matrix[df[\"index_ord\"].values, :, :],\n",
    "            trial_window,\n",
    "        )\n",
    "        ax[2].legend_.set_visible(False)\n",
    "        fig.suptitle(f\"Subject {subject}\")\n",
    "        fig.savefig(DERIVED_PATH / f\"block_switch_choice_patterns_subject_{subject}.svg\")\n",
    "\n",
    "## Check if there are biases depending on the odor patch switched to\n",
    "for (subject, high_patch_index), df in switch_trials_df.groupby([\"subject\", \"after_high_index\"]):\n",
    "    fig, ax = plot_block_switch_choice_patterns(\n",
    "        choice_behavior_matrix[df[\"index_ord\"].values, :, :],\n",
    "        trial_window,\n",
    "    )\n",
    "    fig.suptitle(f\"Subject {subject}, After High Patch Index {high_patch_index}\")\n",
    "    fig.savefig(\n",
    "        DERIVED_PATH / f\"block_switch_choice_patterns_subject_{subject}_after_high_patch_{high_patch_index}.svg\"\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45480eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = {\n",
    "    \"low first rewarded\": lambda row: not row[\"is_high_reward_patch\"] and (row[\"is_rewarded\"] == True),\n",
    "    \"low first not rewarded\": lambda row: not row[\"is_high_reward_patch\"] and (row[\"is_rewarded\"] != True),\n",
    "    \"low first not stop\": lambda row: not row[\"is_high_reward_patch\"] and (row[\"is_choice\"] == False),\n",
    "}\n",
    "\n",
    "for condition_name, condition_fn in conditions.items():\n",
    "    condition_df = switch_trials_df[switch_trials_df.apply(condition_fn, axis=1)]\n",
    "    fig, ax = plot_block_switch_choice_patterns(\n",
    "        choice_behavior_matrix[condition_df[\"index_ord\"].values, :, :],\n",
    "        trial_window,\n",
    "    )\n",
    "    fig.suptitle(f\"All subjects - Condition: {condition_name}\")\n",
    "    fig.savefig(\n",
    "        DERIVED_PATH / f\"block_switch_choice_patterns_all_subjects_condition_{condition_name.replace(' ', '_')}.svg\"\n",
    "    )\n",
    "    for subject in condition_df[\"subject\"].unique():\n",
    "        subject_condition_df = condition_df[condition_df[\"subject\"] == subject]\n",
    "        fig, ax = plot_block_switch_choice_patterns(\n",
    "            choice_behavior_matrix[subject_condition_df[\"index_ord\"].values, :, :],\n",
    "            trial_window,\n",
    "        )\n",
    "        fig.suptitle(f\"All subjects - Condition: {condition_name} - Subject: {subject}\")\n",
    "        fig.savefig(\n",
    "            DERIVED_PATH\n",
    "            / f\"block_switch_choice_patterns_all_subjects_condition_{condition_name.replace(' ', '_')}_{subject}.svg\"\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69991ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab P(Stay) on the \"low patch\" after not getting reward on the high patch\n",
    "high_patch = all_trials_df[all_trials_df[\"is_high_reward_patch\"] & (all_trials_df[\"is_rewarded\"].notna())]\n",
    "import numpy as np\n",
    "\n",
    "with viz.a_lot_of_style():\n",
    "    plt.figure(figsize=(3, 4))\n",
    "    animals = []\n",
    "    for subject, subject_df in all_trials_df.groupby(\"subject\"):\n",
    "        out = {True: 0, False: 0}\n",
    "        for l, sub_df in subject_df.groupby(\"is_rewarded\"):\n",
    "            next_trial = all_trials_df.loc[sub_df.index + 1, :]\n",
    "            next_trial_low_outside_switch = next_trial[\n",
    "                ~next_trial[\"is_high_reward_patch\"] & (next_trial[\"trials_from_last_block_by_trial_type\"] > 0)\n",
    "            ]\n",
    "\n",
    "            # Bootstrap\n",
    "            n_boot = 1000\n",
    "            res = np.random.choice(\n",
    "                next_trial_low_outside_switch[\"is_choice\"],\n",
    "                size=(n_boot, len(next_trial_low_outside_switch)),\n",
    "                replace=True,\n",
    "            )\n",
    "            boot_means = np.nanmean(res, axis=1)\n",
    "\n",
    "            mean_val = np.mean(next_trial_low_outside_switch[\"is_choice\"])\n",
    "            ci_low, ci_high = np.percentile(boot_means, [2.5, 97.5])\n",
    "            out[l] = mean_val\n",
    "\n",
    "            plt.scatter([l], [mean_val], color=subject_colors[subject])\n",
    "            plt.errorbar(\n",
    "                [l],\n",
    "                [mean_val],\n",
    "                yerr=[[mean_val - ci_low], [ci_high - mean_val]],\n",
    "                color=subject_colors[subject],\n",
    "                fmt=\"o\",\n",
    "            )\n",
    "\n",
    "        plt.plot(\n",
    "            [0, 1], [out[False], out[True]], marker=None, label=f\"Subject {subject}\", color=subject_colors[subject]\n",
    "        )\n",
    "        animals.append(out)\n",
    "\n",
    "    plt.plot(\n",
    "        [0, 1],\n",
    "        [np.mean(np.array([out[False] for out in animals])), np.mean(np.array([out[True] for out in animals]))],\n",
    "        marker=\"o\",\n",
    "        color=\"k\",\n",
    "        linewidth=3,\n",
    "    )\n",
    "    plt.xticks([0, 1], [\"Not Rewarded\", \"Rewarded\"])\n",
    "    plt.ylabel(\"P(Stay)\")\n",
    "    plt.title(\"P(Stay) on Low Patch after High Patch Trial Outcome\")\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1.02, 1))\n",
    "    plt.savefig(DERIVED_PATH / \"p_stay_on_low_patch_after_high_patch_outcome.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6987050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from ssvr.analysis.block_switching_behavior import calculate_consecutive_choice_runs, plot_trials_to_criterion_histogram\n",
    "\n",
    "n_consecutive = 3\n",
    "consecutive_runs_df = calculate_consecutive_choice_runs(\n",
    "    all_trials_df, switch_trials_df, n_consecutive=n_consecutive, max_trials_ahead=40\n",
    ")\n",
    "\n",
    "with viz.a_lot_of_style():\n",
    "    fig, axes = plt.subplots(1, 1)\n",
    "\n",
    "    plot_trials_to_criterion_histogram(consecutive_runs_df, ax=axes)\n",
    "    axes.vlines(n_consecutive, 0, axes.get_ylim()[1], colors=\"green\", linestyles=\"dashed\")\n",
    "    fig.savefig(DERIVED_PATH / \"trials_to_criterion_all_subjects.svg\")\n",
    "    plt.show()\n",
    "\n",
    "    for subject, subject_df in consecutive_runs_df.groupby(\"subject\"):\n",
    "        fig, axes = plt.subplots(1, 1)\n",
    "\n",
    "        plot_trials_to_criterion_histogram(subject_df, ax=axes)\n",
    "        axes.vlines(n_consecutive, 0, axes.get_ylim()[1], colors=\"green\", linestyles=\"dashed\")\n",
    "        fig.suptitle(f\"Animal {subject}\")\n",
    "        fig.savefig(DERIVED_PATH / f\"trials_to_criterion_animal_{subject}.svg\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "summary_stats = []\n",
    "\n",
    "for subject, subject_df in consecutive_runs_df.groupby(\"subject\"):\n",
    "    subject_df = subject_df.sort_values(\"trial_index\")\n",
    "\n",
    "    unique_trials = subject_df[\"trial_index\"].unique()\n",
    "    mid_point = len(unique_trials) // 2\n",
    "\n",
    "    first_half_df = subject_df[subject_df[\"trial_index\"].isin(unique_trials[:mid_point])]\n",
    "    second_half_df = subject_df[subject_df[\"trial_index\"].isin(unique_trials[mid_point:])]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 5), sharey=True)\n",
    "    plot_trials_to_criterion_histogram(first_half_df, ax=axes[0], title=\"First Half\")\n",
    "    plot_trials_to_criterion_histogram(second_half_df, ax=axes[1], title=\"Second Half\")\n",
    "\n",
    "    fig.suptitle(f\"Animal {subject} - Split Half Analysis\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(DERIVED_PATH / f\"trials_to_criterion_split_animal_{subject}.svg\")\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate Medians for Summary\n",
    "    def get_medians(df):\n",
    "        low = df[df[\"is_low_reward_patch\"]][\"trials_to_n_consecutive_false\"].dropna()\n",
    "        high = df[~df[\"is_low_reward_patch\"]][\"trials_to_n_consecutive_true\"].dropna()\n",
    "        return (np.median(low) if len(low) > 0 else np.nan, np.median(high) if len(high) > 0 else np.nan)\n",
    "\n",
    "    l1, h1 = get_medians(first_half_df)\n",
    "    l2, h2 = get_medians(second_half_df)\n",
    "\n",
    "    summary_stats.append({\"subject\": subject, \"low_1st\": l1, \"high_1st\": h1, \"low_2nd\": l2, \"high_2nd\": h2})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "fig_sum, ax_sum = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for _, row in summary_df.iterrows():\n",
    "    # Low Reward (Blue)\n",
    "    ax_sum.plot([0, 1], [row[\"low_1st\"], row[\"low_2nd\"]], \"o-\", color=\"blue\", alpha=0.5)\n",
    "    # High Reward (Red)\n",
    "    ax_sum.plot([0, 1], [row[\"high_1st\"], row[\"high_2nd\"]], \"o-\", color=\"red\", alpha=0.5)\n",
    "\n",
    "ax_sum.set_xticks([0, 1])\n",
    "ax_sum.set_xticklabels([\"1st Half\", \"2nd Half\"])\n",
    "ax_sum.set_ylabel(\"Median Trials to Criterion\")\n",
    "ax_sum.set_title(\"Change in Performance Across Session Halves\")\n",
    "ax_sum.grid(True, alpha=0.3)\n",
    "\n",
    "# Custom legend\n",
    "custom_lines = [Line2D([0], [0], color=\"blue\", lw=2, marker=\"o\"), Line2D([0], [0], color=\"red\", lw=2, marker=\"o\")]\n",
    "ax_sum.legend(custom_lines, [\"Low Reward Patch\", \"High Reward Patch\"])\n",
    "\n",
    "fig_sum.savefig(DERIVED_PATH / \"trials_to_criterion_summary_split.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1163694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssvr.analysis.logistic_regression import (\n",
    "    create_regression_design_matrix,\n",
    "    fit_logistic_regression,\n",
    "    perform_bootstrap_regression,\n",
    "    perform_cross_validation,\n",
    "    plot_regression_coefficients,\n",
    "    plot_regression_coefficients_with_ci,\n",
    ")\n",
    "\n",
    "with viz.a_lot_of_style():\n",
    "    # 1. Prepare Data\n",
    "    n_back = 10\n",
    "    fit_intercept = True\n",
    "    regression_df, feature_cols = create_regression_design_matrix(all_trials_df, n_back=n_back)\n",
    "\n",
    "    print(f\"Data shape after cleaning: {regression_df.shape}\")\n",
    "\n",
    "    # 2. Cross Validation (Pooled)\n",
    "    print(\"\\n--- Cross Validation Results (Pooled) ---\")\n",
    "    scores_all = perform_cross_validation(regression_df, feature_cols, cv=5, fit_intercept=fit_intercept)\n",
    "    print(f\"All Subjects CV Accuracy: {scores_all.mean():.3f} (+/- {scores_all.std() * 2:.3f})\")\n",
    "\n",
    "    # 3. Bootstrapping for Confidence Intervals (Pooled)\n",
    "    print(\"\\n--- Bootstrapping Confidence Intervals (Pooled) ---\")\n",
    "    n_bootstraps = 100\n",
    "    print(f\"Running {n_bootstraps} bootstraps...\")\n",
    "    coefs_boot, intercepts_boot, scores_boot = perform_bootstrap_regression(\n",
    "        regression_df, feature_cols, n_bootstraps=n_bootstraps, fit_intercept=fit_intercept\n",
    "    )\n",
    "    print(f\"Bootstrap OOB Accuracy: {scores_boot.mean():.3f} (+/- {scores_boot.std() * 2:.3f})\")\n",
    "\n",
    "    fig_ci, ax_ci = plot_regression_coefficients_with_ci(coefs_boot, intercepts_boot, n_back)\n",
    "    fig_ci.suptitle(\"Logistic Regression with 95% CI (All Subjects)\")\n",
    "    fig_ci.savefig(DERIVED_PATH / \"logistic_regression_coefficients_all_ci.svg\")\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Per Subject\n",
    "    for subject, subject_df in regression_df.groupby(\"subject\"):\n",
    "        print(f\"\\nProcessing Subject {subject}...\")\n",
    "\n",
    "        scores_subj = perform_cross_validation(subject_df, feature_cols, cv=5, fit_intercept=fit_intercept)\n",
    "        print(f\"  CV Accuracy: {scores_subj.mean():.3f} (+/- {scores_subj.std() * 2:.3f})\")\n",
    "\n",
    "        print(f\"  Running bootstraps for {subject}...\")\n",
    "        coefs_subj_boot, intercepts_subj_boot, scores_subj_boot = perform_bootstrap_regression(\n",
    "            subject_df, feature_cols, n_bootstraps=n_bootstraps, fit_intercept=fit_intercept\n",
    "        )\n",
    "        print(f\"  Bootstrap OOB Accuracy: {scores_subj_boot.mean():.3f} (+/- {scores_subj_boot.std() * 2:.3f})\")\n",
    "\n",
    "        fig_subj_ci, ax_subj_ci = plot_regression_coefficients_with_ci(\n",
    "            coefs_subj_boot,\n",
    "            intercepts_subj_boot,\n",
    "            n_back,\n",
    "        )\n",
    "        fig_subj_ci.suptitle(f\"Logistic Regression with 95% CI: Subject {subject}\")\n",
    "        fig_subj_ci.savefig(DERIVED_PATH / f\"logistic_regression_coefficients_{subject}_ci.svg\")\n",
    "        plt.show()\n",
    "\n",
    "    # 5. Negative Control (Shuffled Labels)\n",
    "    print(\"\\n--- Negative Control (Shuffled Labels) ---\")\n",
    "    shuffled_df = regression_df.copy()\n",
    "    shuffled_df[\"is_choice\"] = np.random.permutation(shuffled_df[\"is_choice\"].values)\n",
    "\n",
    "    # Fit & CV on Shuffled Data (Pooled)\n",
    "    scores_shuffled = perform_cross_validation(shuffled_df, feature_cols, cv=5, fit_intercept=fit_intercept)\n",
    "    print(f\"Shuffled Labels CV Accuracy: {scores_shuffled.mean():.3f} (+/- {scores_shuffled.std() * 2:.3f})\")\n",
    "\n",
    "    # For negative control, we can just show the standard plot as a quick check, or bootstrap it too.\n",
    "    # Standard plot is faster and sufficient to show it's noise.\n",
    "    model_shuffled = fit_logistic_regression(shuffled_df, feature_cols, fit_intercept=fit_intercept)\n",
    "    fig, ax = plot_regression_coefficients(model_shuffled, n_back)\n",
    "    fig.suptitle(\"Logistic Regression: Shuffled Control (All Subjects)\")\n",
    "    fig.savefig(DERIVED_PATH / \"logistic_regression_coefficients_shuffled.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9ab8a",
   "metadata": {},
   "source": [
    "I think plotting the distributions here is fair because:\n",
    "- the distribution of underlying delays is the same across patches\n",
    "- We are asking: \n",
    "  * Given trials where the animal did not make a stop, where do the \"leave times\" cluster?\n",
    "  * Given trials where the animal did make a choice, where do the times cluster?\n",
    "  * Are they willing to wait less in both cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"is_high_reward_patch\"] = all_trials_df[\"patch_index\"] == all_trials_df[\"high_patch_index\"]\n",
    "mask_for_variable_stop = (~all_trials_df[\"is_fixed_stop_duration\"]) & (\n",
    "    all_trials_df[\"trials_from_last_block_by_trial_type\"] > 5\n",
    ")\n",
    "# mask_for_variable_stop = (all_trials_df[\"is_fixed_stop_duration\"]) & (all_trials_df[\"trials_from_last_block_by_trial_type\"] > 5)\n",
    "\n",
    "filtered_df = all_trials_df[mask_for_variable_stop]\n",
    "\n",
    "\n",
    "def calculate_hazard_with_censoring(non_completed_data, all_data, bins):\n",
    "    \"\"\"\n",
    "    Calculate hazard function accounting for censored observations.\n",
    "\n",
    "    Parameters:\n",
    "    - non_completed_data: Times for non-completed trials (events)\n",
    "    - all_data: Times for all trials (completed + non-completed)\n",
    "    - bins: Bin edges for the histogram\n",
    "\n",
    "    Returns:\n",
    "    - hazard: Array of hazard rates for each bin\n",
    "    \"\"\"\n",
    "    # Count non-completed trials in each bin (numerator)\n",
    "    non_completed_counts, _ = np.histogram(non_completed_data, bins=bins)\n",
    "\n",
    "    # For each bin, count all trials (completed + non-completed) with times >= bin edge (denominator)\n",
    "    hazard = np.zeros(len(bins) - 1)\n",
    "    for i in range(len(bins) - 1):\n",
    "        at_risk = np.sum(all_data >= bins[i])\n",
    "        if at_risk > 0:\n",
    "            hazard[i] = non_completed_counts[i] / at_risk\n",
    "\n",
    "    return hazard\n",
    "\n",
    "\n",
    "choices = [False, True]\n",
    "bin_width = 0.25\n",
    "max_time = 7.1\n",
    "bins = np.arange(0, max_time + bin_width, bin_width)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "for subject, subject_df in filtered_df.groupby(\"subject\"):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharex=True)\n",
    "\n",
    "    is_choice_times_data = {False: {}, True: {}}\n",
    "\n",
    "    for i, is_choice in enumerate(choices):\n",
    "        ax = axes[i]\n",
    "        subset = subject_df[subject_df[\"is_choice\"] == is_choice]\n",
    "\n",
    "        for is_high_patch in [False, True]:\n",
    "            sub_subset = subset[subset[\"is_high_reward_patch\"] == is_high_patch]\n",
    "            if is_choice:\n",
    "                stop_duration = (sub_subset[\"choice_time\"] - sub_subset[\"stop_time\"]).dropna()\n",
    "            else:\n",
    "                stop_duration = sub_subset[\"longest_stop_duration\"].dropna()\n",
    "            stop_duration = stop_duration[stop_duration <= max_time]\n",
    "\n",
    "            is_choice_times_data[is_choice][is_high_patch] = stop_duration\n",
    "\n",
    "            if len(stop_duration) == 0:\n",
    "                continue\n",
    "\n",
    "            label = \"High Reward\" if is_high_patch else \"Low Reward\"\n",
    "            color = \"red\" if is_high_patch else \"blue\"\n",
    "\n",
    "        # For this patch type (is_high), get both completed and non-completed trials\n",
    "    for i, is_choice in enumerate(choices):\n",
    "        ax = axes[i]\n",
    "        choices = is_choice_times_data[is_choice]\n",
    "        for is_high_patch in [False, True]:\n",
    "            color = \"red\" if is_high_patch else \"blue\"\n",
    "            label = \"High Reward\" if is_high_patch else \"Low Reward\"\n",
    "            patch_choices = choices[is_high_patch]\n",
    "            # Histogram: show non-completed as fraction of total trials\n",
    "            weights = np.ones_like(patch_choices) / len(patch_choices)\n",
    "            ax.hist(patch_choices, bins=bins, alpha=0.3, weights=weights, label=label, color=color)\n",
    "\n",
    "            # Median\n",
    "            median_val = patch_choices.median()\n",
    "            ax.axvline(median_val, color=color, linestyle=\"--\", linewidth=2, label=f\"Median: {median_val:.2f}\")\n",
    "\n",
    "            ax.set_title(f\"Is Choice: {is_choice}\")\n",
    "            ax.set_xlabel(\"Time (s)\")\n",
    "            ax.set_ylabel(\"Fraction of Total Trials\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc=\"upper right\")\n",
    "\n",
    "    # Third plot: Hazard rate with bootstrap confidence intervals\n",
    "    ax_hazard = axes[2]\n",
    "    n_bootstraps = 1000\n",
    "\n",
    "    for is_high_patch in [False, True]:\n",
    "        non_completed = is_choice_times_data[False].get(is_high_patch)\n",
    "        completed = is_choice_times_data[True].get(is_high_patch)\n",
    "\n",
    "        if non_completed is None or len(non_completed) == 0:\n",
    "            continue\n",
    "\n",
    "        label = \"High Reward\" if is_high_patch else \"Low Reward\"\n",
    "        color = \"red\" if is_high_patch else \"blue\"\n",
    "\n",
    "        # Combine all trials for hazard calculation\n",
    "        if completed is not None and len(completed) > 0:\n",
    "            all_trials = pd.concat([non_completed, completed])\n",
    "        else:\n",
    "            all_trials = non_completed\n",
    "\n",
    "        # Bootstrap for confidence intervals\n",
    "        boot_hazards = []\n",
    "        nc_vals = non_completed.values\n",
    "        all_vals = all_trials.values\n",
    "\n",
    "        for _ in range(n_bootstraps):\n",
    "            # Resample with replacement\n",
    "            nc_sample = np.random.choice(nc_vals, size=len(nc_vals), replace=True)\n",
    "            all_sample = np.random.choice(all_vals, size=len(all_vals), replace=True)\n",
    "\n",
    "            # Calculate hazard for this bootstrap sample\n",
    "            boot_haz = calculate_hazard_with_censoring(nc_sample, all_sample, bins)\n",
    "            boot_hazards.append(boot_haz)\n",
    "\n",
    "        boot_hazards = np.array(boot_hazards)\n",
    "        mean_hazard = np.mean(boot_hazards, axis=0)\n",
    "        ci_lower = np.percentile(boot_hazards, 2.5, axis=0)\n",
    "        ci_upper = np.percentile(boot_hazards, 97.5, axis=0)\n",
    "\n",
    "        # Plot mean hazard with confidence interval\n",
    "        ax_hazard.plot(bin_centers, mean_hazard, color=color, linestyle=\"-\", linewidth=2, label=label, marker=\"o\")\n",
    "        ax_hazard.fill_between(bin_centers, ci_lower, ci_upper, color=color, alpha=0.2)\n",
    "\n",
    "    ax_hazard.set_ylabel(\"Hazard Rate\")\n",
    "    ax_hazard.set_xlabel(\"Time (s)\")\n",
    "    ax_hazard.set_title(\"Hazard rate of non-completed trials\")\n",
    "    ax_hazard.legend(loc=\"upper right\")\n",
    "    ax_hazard.grid(True, alpha=0.3)\n",
    "    ax_hazard.set_ylim(bottom=0, top=1)\n",
    "\n",
    "    fig.suptitle(f\"Subject {subject}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa28e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in session_datasets[0:1]:\n",
    "    print(f\"Session: {dataset.session_info.session_id} ({dataset.session_info.subject})\")\n",
    "    ax_velocity, ax_events = viz.plot_ethogram(\n",
    "        dataset,\n",
    "        t_start=dataset.trials[\"odor_onset_time\"][30],\n",
    "        t_end=dataset.trials[\"odor_onset_time\"][40],\n",
    "        figsize=(12, 3),\n",
    "    )\n",
    "    dataset.dataset[\"Behavior\"][\"OperationControl\"]\n",
    "\n",
    "    unique_patches = dataset.trials[\"patch_index\"].unique()\n",
    "\n",
    "    pairwise_style = {\n",
    "        (patch_idx, is_choice): {\n",
    "            \"color\": viz.patch_index_colormap[patch_idx],\n",
    "            \"linestyle\": choice_linestyle[is_choice],\n",
    "            \"alpha\": 0.02,\n",
    "        }\n",
    "        for patch_idx in unique_patches\n",
    "        for is_choice in [True, False]\n",
    "    }\n",
    "\n",
    "    fig, ax = viz.plot_aligned_to_grouped_by(\n",
    "        timestamp_df=dataset.trials,\n",
    "        timeseries=dataset.processed_streams.sniff_ipi_frequency[\"frequency\"],\n",
    "        by=[\"patch_index\", \"is_choice\"],\n",
    "        timestamp_column=\"odor_onset_time\",\n",
    "        plot_kwargs=pairwise_style,\n",
    "        event_window=(-2, 5),\n",
    "    )\n",
    "    ax.set_ylabel(\"Sniff Frequency (Hz)\")\n",
    "\n",
    "    fig, ax = viz.plot_aligned_to_grouped_by(\n",
    "        timestamp_df=dataset.trials,\n",
    "        timeseries=dataset.processed_streams.position_velocity[\"velocity\"],\n",
    "        by=[\"patch_index\", \"is_choice\"],\n",
    "        timestamp_column=\"odor_onset_time\",\n",
    "        plot_kwargs=pairwise_style,\n",
    "        event_window=(-2, 5),\n",
    "    )\n",
    "    ax.set_ylabel(\"Velocity (cm/s)\")\n",
    "\n",
    "    fig, ax = viz.plot_aligned_to_grouped_by(\n",
    "        timestamp_df=dataset.trials,\n",
    "        timeseries=dataset.processed_streams.lickometer.frequency,\n",
    "        by=[\"patch_index\", \"is_choice\"],\n",
    "        timestamp_column=\"odor_onset_time\",\n",
    "        plot_kwargs=pairwise_style,\n",
    "        event_window=(-2, 5),\n",
    "    )\n",
    "    ax.set_ylabel(\"Lick rate (Hz)\")\n",
    "\n",
    "    pairwise_style = {\n",
    "        (p_reward, is_choice): {\n",
    "            \"color\": \"red\" if p_reward > 0.5 else \"blue\",\n",
    "            \"linestyle\": choice_linestyle[is_choice],\n",
    "            \"alpha\": 0.02,\n",
    "        }\n",
    "        for p_reward in np.unique(dataset.trials[\"p_reward\"].values)\n",
    "        for is_choice in [True, False]\n",
    "    }\n",
    "\n",
    "    fig, ax = viz.plot_aligned_to_grouped_by(\n",
    "        timestamp_df=dataset.trials.query(\"p_reward < 1.0\"),\n",
    "        timeseries=dataset.processed_streams.sniff_ipi_frequency[\"frequency\"],\n",
    "        by=[\"p_reward\", \"is_choice\"],\n",
    "        timestamp_column=\"odor_onset_time\",\n",
    "        plot_kwargs=pairwise_style,\n",
    "        event_window=(-2, 5),\n",
    "    )\n",
    "\n",
    "    fig, ax = viz.plot_aligned_to_grouped_by(\n",
    "        timestamp_df=dataset.trials.query(\"p_reward < 1.0\"),\n",
    "        timeseries=dataset.processed_streams.position_velocity[\"velocity\"],\n",
    "        by=[\"p_reward\", \"is_choice\"],\n",
    "        timestamp_column=\"odor_onset_time\",\n",
    "        plot_kwargs=pairwise_style,\n",
    "        event_window=(-2, 5),\n",
    "    )\n",
    "\n",
    "    fig, ax = viz.plot_aligned_to_grouped_by(\n",
    "        timestamp_df=dataset.trials.query(\"p_reward < 1.0\"),\n",
    "        timeseries=dataset.processed_streams.lickometer.frequency,\n",
    "        by=[\"p_reward\", \"is_choice\"],\n",
    "        timestamp_column=\"odor_onset_time\",\n",
    "        plot_kwargs=pairwise_style,\n",
    "        event_window=(-2, 5),\n",
    "    )\n",
    "\n",
    "    ax = viz.plot_session_trials(dataset, alpha=0.33, figsize=(16, 6))\n",
    "\n",
    "    time_of_trial = dataset.trials[\"odor_onset_time\"]\n",
    "\n",
    "    blocks = dataset.dataset[\"Behavior\"][\"SoftwareEvents\"][\"Block\"].load().data.copy()\n",
    "    block_times = blocks.index.values\n",
    "    trial_indices = time_of_trial.searchsorted(block_times, side=\"right\") - 1\n",
    "    trial_indices = np.maximum(trial_indices, 0)\n",
    "    blocks[\"trial_idx\"] = time_of_trial.iloc[trial_indices].index.values\n",
    "    ax.vlines(\n",
    "        blocks[\"trial_idx\"].values,\n",
    "        ymin=ax.get_ylim()[0],\n",
    "        ymax=ax.get_ylim()[1],\n",
    "        colors=\"k\",\n",
    "        linestyles=\"dashed\",\n",
    "        label=\"Block Change\",\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eda666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_style = {\n",
    "    (patch_quality, is_choice): {\n",
    "        \"color\": \"red\" if patch_quality else \"blue\",\n",
    "        \"linestyle\": choice_linestyle[is_choice],\n",
    "        \"alpha\": 0.02,\n",
    "    }\n",
    "    for patch_quality in [True, False]\n",
    "    for is_choice in [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "def make_legend(pairwise_style):\n",
    "    custom_lines = []\n",
    "    labels = []\n",
    "    added = set()\n",
    "    for (patch_quality, is_choice), style in pairwise_style.items():\n",
    "        label = f\"{'High Reward' if patch_quality else 'Low Reward'} - {'Choice' if is_choice else 'No Choice'}\"\n",
    "        if label not in added:\n",
    "            line = plt.Line2D([0], [0], color=style[\"color\"], linestyle=style[\"linestyle\"])\n",
    "            custom_lines.append(line)\n",
    "            labels.append(label)\n",
    "            added.add(label)\n",
    "    return custom_lines, labels\n",
    "\n",
    "\n",
    "streams = [\n",
    "    (lambda d: d.processed_streams.sniff_ipi_frequency[\"frequency\"], \"Sniff Frequency Aligned to Odor Onset\", (1, 10)),\n",
    "    (lambda d: d.processed_streams.position_velocity[\"velocity\"], \"Velocity Aligned to Odor Onset\", (-5, 60)),\n",
    "    (lambda d: d.processed_streams.lickometer.frequency, \"Lick Rate Aligned to Odor Onset\", (0, 10)),\n",
    "]\n",
    "WINDOW = (-2, 5)\n",
    "\n",
    "with viz.a_lot_of_style():\n",
    "    for stream_fn, stream_label, y_limits in streams:\n",
    "        fig, axs = plt.subplots(1, len(all_trials_df[\"subject\"].unique()), figsize=(20, 5), sharex=True, sharey=True)\n",
    "\n",
    "        for i, subject in enumerate(all_trials_df[\"subject\"].unique()):\n",
    "            _, ax = viz.plot_aligned_to_grouped_by(\n",
    "                timestamp_df=[\n",
    "                    d.trials.query(\"trials_from_last_block_by_trial_type > 5\")\n",
    "                    for d in session_datasets\n",
    "                    if d.session_info.subject == subject\n",
    "                ],\n",
    "                timeseries=[stream_fn(d) for d in session_datasets if d.session_info.subject == subject],\n",
    "                by=[\"is_high_reward_patch\", \"is_choice\"],\n",
    "                timestamp_column=\"odor_onset_time\",\n",
    "                event_window=WINDOW,\n",
    "                time_bin_width=0.025,\n",
    "                plot_kwargs=pairwise_style,\n",
    "                agg_plot_kwarg_modifier={\"linewidth\": 3, \"alpha\": 1},\n",
    "                agg_spread_kwarg_modifier={\"alpha\": 0.05, \"linewidth\": 0},\n",
    "                ax=axs[i],\n",
    "            )\n",
    "            ax.set_xlim(WINDOW[0], WINDOW[1])\n",
    "            ax.set_ylim(y_limits[0], y_limits[1])\n",
    "            ax.vlines(0, ymin=ax.get_ylim()[0], ymax=ax.get_ylim()[1], colors=\"k\", linestyles=\"dashed\")\n",
    "            ax.set_xlabel(f\"Time from Odor Onset (s) \\n Subject {subject}\")\n",
    "        fig.suptitle(stream_label)\n",
    "        fig.legend(*make_legend(pairwise_style), loc=\"upper right\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssvr (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
